{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fbf38ad2f4ccaa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Guidance for training a model with your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e474201f7f64ab4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356a8bc9c1e1349c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:01:15.177812Z",
     "start_time": "2024-06-13T12:01:14.568408500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from softs.exp.exp_custom import Exp_Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b69019515b59d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e886ee3de8bbb1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:01:15.242241600Z",
     "start_time": "2024-06-13T12:01:15.178809900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(root_path='./dataset/ETT-small/', data_path='ETTm1.csv', data='ETTm1', features='M', freq='h', seq_len=96, pred_len=96, model='SOFTS', checkpoints='./checkpoints/', d_model=128, d_core=64, d_ff=128, e_layers=2, learning_rate=0.0003, lradj='cosine', train_epochs=50, patience=3, batch_size=16, dropout=0.0, activation='gelu', use_norm=True, num_workers=0, use_gpu=False, gpu='0', save_model=True, loss_func='huber')\n"
     ]
    }
   ],
   "source": [
    "# fix seed for reproducibility\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.set_num_threads(6)\n",
    "\n",
    "# basic config\n",
    "config = {\n",
    "    # dataset settings\n",
    "    \"root_path\": \"./dataset/ETT-small/\",\n",
    "    \"data_path\": \"ETTm1.csv\",\n",
    "    \"data\": \"ETTm1\",\n",
    "    \"features\": \"M\",\n",
    "    \"freq\": \"h\",\n",
    "    \"seq_len\": 96,\n",
    "    \"pred_len\": 96,\n",
    "    # model settings\n",
    "    \"model\": \"SOFTS\",\n",
    "    \"checkpoints\": \"./checkpoints/\",\n",
    "    \"d_model\": 128,\n",
    "    \"d_core\": 64,\n",
    "    \"d_ff\": 128,\n",
    "    \"e_layers\": 2,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"lradj\": \"cosine\",\n",
    "    \"train_epochs\": 50,\n",
    "    \"patience\": 3,\n",
    "    \"batch_size\": 16,\n",
    "    \"dropout\": 0.0,\n",
    "    \"activation\": \"gelu\",\n",
    "    \"use_norm\": True,\n",
    "    # system settings\n",
    "    \"num_workers\": 0,\n",
    "    \"use_gpu\": True,\n",
    "    \"gpu\": \"0\",\n",
    "    \"save_model\": True,\n",
    "    \"loss_func\": \"huber\",\n",
    "}\n",
    "\n",
    "parser = argparse.ArgumentParser(description='SOFTS')\n",
    "args = parser.parse_args([])\n",
    "args.__dict__.update(config)\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fc13ff2726f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Prepare the dataset\n",
    "Organize your data in the following format:\n",
    "- The dataset should be a csv file.\n",
    "- If there is a time feature, the first column contains timestamps in the format 'YYYY-MM-DD HH:MM:SS'. If there's no time feature, the dataset starts directly with the features.\n",
    "- If the parameter `features` is 'M', the following columns are both the features and the targets. If `features` is 'MS', the following columns are the features, and the last column is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc7a801398c68de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:01:15.594744200Z",
     "start_time": "2024-06-13T12:01:15.246228700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
      "1  2016-07-01 00:15:00  5.760  2.076  1.492  0.426  4.264  1.401  30.459999\n",
      "2  2016-07-01 00:30:00  5.760  1.942  1.492  0.391  4.234  1.310  30.038000\n",
      "3  2016-07-01 00:45:00  5.760  1.942  1.492  0.426  4.234  1.310  27.013000\n",
      "4  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "print(data.head())\n",
    "\n",
    "# split data\n",
    "train_data = data.iloc[: 12 * 30 * 24 * 4]\n",
    "vali_data = data.iloc[12 * 30 * 24 * 4 - args.seq_len: 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4]\n",
    "test_data = data.iloc[12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - args.seq_len: 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
    "\n",
    "# optional: scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if 'date' in train_data.columns:\n",
    "    scaler.fit(train_data.iloc[:, 1:])\n",
    "    train_data.iloc[:, 1:] = scaler.transform(train_data.iloc[:, 1:])\n",
    "    vali_data.iloc[:, 1:] = scaler.transform(vali_data.iloc[:, 1:])\n",
    "    test_data.iloc[:, 1:] = scaler.transform(test_data.iloc[:, 1:])\n",
    "else:\n",
    "    scaler.fit(train_data.iloc[:, :])\n",
    "    train_data.iloc[:, :] = scaler.transform(train_data.iloc[:, :])\n",
    "    vali_data.iloc[:, :] = scaler.transform(vali_data.iloc[:, :])\n",
    "    test_data.iloc[:, :] = scaler.transform(test_data.iloc[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cef58eb7d57d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Train and Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77857ed9da69bd61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:02:52.982915200Z",
     "start_time": "2024-06-13T12:01:15.589759400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      ">>>>>>>start training : ETTm1_SOFTS_96_96>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\titers: 100, epoch: 1 | loss: 0.1774055\n",
      "\tspeed: 0.0318s/iter; left time: 3410.6829s\n",
      "\titers: 200, epoch: 1 | loss: 0.1016285\n",
      "\tspeed: 0.0211s/iter; left time: 2259.9480s\n",
      "\titers: 300, epoch: 1 | loss: 0.1712743\n",
      "\tspeed: 0.0249s/iter; left time: 2672.9192s\n",
      "\titers: 400, epoch: 1 | loss: 0.1048555\n",
      "\tspeed: 0.0295s/iter; left time: 3154.4056s\n",
      "\titers: 500, epoch: 1 | loss: 0.1215826\n",
      "\tspeed: 0.0280s/iter; left time: 2995.3636s\n",
      "\titers: 600, epoch: 1 | loss: 0.1622979\n",
      "\tspeed: 0.0256s/iter; left time: 2734.6055s\n",
      "\titers: 700, epoch: 1 | loss: 0.1366529\n",
      "\tspeed: 0.0242s/iter; left time: 2585.4898s\n",
      "\titers: 800, epoch: 1 | loss: 0.1319874\n",
      "\tspeed: 0.0249s/iter; left time: 2652.5566s\n",
      "\titers: 900, epoch: 1 | loss: 0.1074991\n",
      "\tspeed: 0.0232s/iter; left time: 2474.1516s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1267864\n",
      "\tspeed: 0.0238s/iter; left time: 2536.1783s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1280163\n",
      "\tspeed: 0.0245s/iter; left time: 2607.8372s\n",
      "\titers: 1200, epoch: 1 | loss: 0.0845848\n",
      "\tspeed: 0.0235s/iter; left time: 2493.8076s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1167840\n",
      "\tspeed: 0.0240s/iter; left time: 2552.8116s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1176999\n",
      "\tspeed: 0.0251s/iter; left time: 2666.5218s\n",
      "\titers: 1500, epoch: 1 | loss: 0.1240922\n",
      "\tspeed: 0.0244s/iter; left time: 2584.0314s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1867837\n",
      "\tspeed: 0.0242s/iter; left time: 2559.8287s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0976848\n",
      "\tspeed: 0.0240s/iter; left time: 2534.3977s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1130760\n",
      "\tspeed: 0.0234s/iter; left time: 2475.0195s\n",
      "\titers: 1900, epoch: 1 | loss: 0.1444687\n",
      "\tspeed: 0.0242s/iter; left time: 2549.1676s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1069896\n",
      "\tspeed: 0.0255s/iter; left time: 2692.1839s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1012340\n",
      "\tspeed: 0.0240s/iter; left time: 2526.0651s\n",
      "Epoch: 1 cost time: 52.5061137676239\n",
      "Validation loss decreased (inf --> 0.168797).  Saving model ...\n",
      "Epoch: 1, Steps: 2149 | Train Loss: 0.1268278 Vali Loss: 0.1687966 Test Loss: 0.1335240\n",
      "Updating learning rate to 0.0002997040092642407\n",
      "\titers: 100, epoch: 2 | loss: 0.1377894\n",
      "\tspeed: 0.1331s/iter; left time: 14006.7447s\n",
      "\titers: 200, epoch: 2 | loss: 0.1255761\n",
      "\tspeed: 0.0254s/iter; left time: 2666.9013s\n",
      "\titers: 300, epoch: 2 | loss: 0.1224472\n",
      "\tspeed: 0.0253s/iter; left time: 2661.5289s\n",
      "\titers: 400, epoch: 2 | loss: 0.1096865\n",
      "\tspeed: 0.0244s/iter; left time: 2555.4991s\n",
      "\titers: 500, epoch: 2 | loss: 0.1007382\n",
      "\tspeed: 0.0250s/iter; left time: 2620.0090s\n",
      "\titers: 600, epoch: 2 | loss: 0.1610969\n",
      "\tspeed: 0.0258s/iter; left time: 2705.9017s\n",
      "\titers: 700, epoch: 2 | loss: 0.1261862\n",
      "\tspeed: 0.0273s/iter; left time: 2855.3249s\n",
      "\titers: 800, epoch: 2 | loss: 0.0986705\n",
      "\tspeed: 0.0263s/iter; left time: 2747.6490s\n",
      "\titers: 900, epoch: 2 | loss: 0.1257741\n",
      "\tspeed: 0.0254s/iter; left time: 2652.9590s\n",
      "\titers: 1000, epoch: 2 | loss: 0.1495262\n",
      "\tspeed: 0.0260s/iter; left time: 2706.8247s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1293317\n",
      "\tspeed: 0.0251s/iter; left time: 2615.7631s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1093119\n",
      "\tspeed: 0.0259s/iter; left time: 2692.6793s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0891856\n",
      "\tspeed: 0.0260s/iter; left time: 2700.5554s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1053255\n",
      "\tspeed: 0.0261s/iter; left time: 2712.2184s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1196056\n",
      "\tspeed: 0.0264s/iter; left time: 2744.3589s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0949380\n",
      "\tspeed: 0.0254s/iter; left time: 2639.2147s\n",
      "\titers: 1700, epoch: 2 | loss: 0.1738313\n",
      "\tspeed: 0.0264s/iter; left time: 2730.6967s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1155276\n",
      "\tspeed: 0.0280s/iter; left time: 2899.9129s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1093305\n",
      "\tspeed: 0.0266s/iter; left time: 2754.1671s\n",
      "\titers: 2000, epoch: 2 | loss: 0.1184997\n",
      "\tspeed: 0.0263s/iter; left time: 2721.2361s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1339658\n",
      "\tspeed: 0.0281s/iter; left time: 2896.3958s\n",
      "Epoch: 2 cost time: 55.87827706336975\n",
      "Validation loss decreased (0.168797 --> 0.167652).  Saving model ...\n",
      "Epoch: 2, Steps: 2149 | Train Loss: 0.1217307 Vali Loss: 0.1676521 Test Loss: 0.1336118\n",
      "Updating learning rate to 0.0002988172051971717\n",
      "\titers: 100, epoch: 3 | loss: 0.0897883\n",
      "\tspeed: 0.1465s/iter; left time: 15101.1663s\n",
      "\titers: 200, epoch: 3 | loss: 0.1223698\n",
      "\tspeed: 0.0290s/iter; left time: 2980.6808s\n",
      "\titers: 300, epoch: 3 | loss: 0.1086298\n",
      "\tspeed: 0.0303s/iter; left time: 3114.8362s\n",
      "\titers: 400, epoch: 3 | loss: 0.1302187\n",
      "\tspeed: 0.0289s/iter; left time: 2969.2989s\n",
      "\titers: 500, epoch: 3 | loss: 0.1335228\n",
      "\tspeed: 0.0284s/iter; left time: 2912.8935s\n",
      "\titers: 600, epoch: 3 | loss: 0.1113160\n",
      "\tspeed: 0.0272s/iter; left time: 2789.5678s\n",
      "\titers: 700, epoch: 3 | loss: 0.1139356\n",
      "\tspeed: 0.0294s/iter; left time: 3008.2139s\n",
      "\titers: 800, epoch: 3 | loss: 0.1160374\n",
      "\tspeed: 0.0276s/iter; left time: 2824.9235s\n",
      "\titers: 900, epoch: 3 | loss: 0.1363838\n",
      "\tspeed: 0.0275s/iter; left time: 2813.7481s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0933273\n",
      "\tspeed: 0.0288s/iter; left time: 2941.7428s\n",
      "\titers: 1100, epoch: 3 | loss: 0.1180895\n",
      "\tspeed: 0.0276s/iter; left time: 2819.5772s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1537268\n",
      "\tspeed: 0.0277s/iter; left time: 2821.1403s\n",
      "\titers: 1300, epoch: 3 | loss: 0.1068323\n",
      "\tspeed: 0.0279s/iter; left time: 2843.9111s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1343858\n",
      "\tspeed: 0.0290s/iter; left time: 2953.6922s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1024257\n",
      "\tspeed: 0.0277s/iter; left time: 2813.3516s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1311058\n",
      "\tspeed: 0.0309s/iter; left time: 3136.1761s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1314317\n",
      "\tspeed: 0.0308s/iter; left time: 3121.6751s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1137054\n",
      "\tspeed: 0.0273s/iter; left time: 2768.6243s\n",
      "\titers: 1900, epoch: 3 | loss: 0.1166146\n",
      "\tspeed: 0.0294s/iter; left time: 2976.9508s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1149186\n",
      "\tspeed: 0.0292s/iter; left time: 2957.9513s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0955113\n",
      "\tspeed: 0.0288s/iter; left time: 2907.4031s\n",
      "Epoch: 3 cost time: 61.32562303543091\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3, Steps: 2149 | Train Loss: 0.1178227 Vali Loss: 0.1709080 Test Loss: 0.1355738\n",
      "Updating learning rate to 0.0002973430876093033\n",
      "\titers: 100, epoch: 4 | loss: 0.1131863\n",
      "\tspeed: 0.1631s/iter; left time: 16462.4410s\n",
      "\titers: 200, epoch: 4 | loss: 0.1031335\n",
      "\tspeed: 0.0296s/iter; left time: 2987.1341s\n",
      "\titers: 300, epoch: 4 | loss: 0.1226388\n",
      "\tspeed: 0.0275s/iter; left time: 2773.7586s\n",
      "\titers: 400, epoch: 4 | loss: 0.0934700\n",
      "\tspeed: 0.0296s/iter; left time: 2974.8521s\n",
      "\titers: 500, epoch: 4 | loss: 0.1401499\n",
      "\tspeed: 0.0459s/iter; left time: 4609.4771s\n",
      "\titers: 600, epoch: 4 | loss: 0.1116669\n",
      "\tspeed: 0.0398s/iter; left time: 3994.9769s\n",
      "\titers: 700, epoch: 4 | loss: 0.1218464\n",
      "\tspeed: 0.0352s/iter; left time: 3526.6997s\n",
      "\titers: 800, epoch: 4 | loss: 0.1258495\n",
      "\tspeed: 0.0408s/iter; left time: 4085.9475s\n",
      "\titers: 900, epoch: 4 | loss: 0.1242953\n",
      "\tspeed: 0.0312s/iter; left time: 3119.2036s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0979276\n",
      "\tspeed: 0.0356s/iter; left time: 3557.7542s\n",
      "\titers: 1100, epoch: 4 | loss: 0.1063174\n",
      "\tspeed: 0.0345s/iter; left time: 3445.2584s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1534404\n",
      "\tspeed: 0.0312s/iter; left time: 3117.1472s\n",
      "\titers: 1300, epoch: 4 | loss: 0.1269414\n",
      "\tspeed: 0.0342s/iter; left time: 3411.2734s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1114023\n",
      "\tspeed: 0.0362s/iter; left time: 3602.4445s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1084766\n",
      "\tspeed: 0.0354s/iter; left time: 3517.6435s\n",
      "\titers: 1600, epoch: 4 | loss: 0.1425123\n",
      "\tspeed: 0.0362s/iter; left time: 3603.2379s\n",
      "\titers: 1700, epoch: 4 | loss: 0.1258762\n",
      "\tspeed: 0.0326s/iter; left time: 3240.8052s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1063557\n",
      "\tspeed: 0.0339s/iter; left time: 3362.9850s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0850044\n",
      "\tspeed: 0.0423s/iter; left time: 4196.5886s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1018131\n",
      "\tspeed: 0.0341s/iter; left time: 3372.6268s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1062353\n",
      "\tspeed: 0.0358s/iter; left time: 3545.4967s\n",
      "Epoch: 4 cost time: 75.06496214866638\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4, Steps: 2149 | Train Loss: 0.1156447 Vali Loss: 0.1678643 Test Loss: 0.1298888\n",
      "Updating learning rate to 0.00029528747416929463\n",
      "\titers: 100, epoch: 5 | loss: 0.1056126\n",
      "\tspeed: 0.1817s/iter; left time: 17947.8611s\n",
      "\titers: 200, epoch: 5 | loss: 0.1075883\n",
      "\tspeed: 0.0333s/iter; left time: 3286.2050s\n",
      "\titers: 300, epoch: 5 | loss: 0.0791791\n",
      "\tspeed: 0.0401s/iter; left time: 3953.3100s\n",
      "\titers: 400, epoch: 5 | loss: 0.1171208\n",
      "\tspeed: 0.0522s/iter; left time: 5135.9690s\n",
      "\titers: 500, epoch: 5 | loss: 0.1233198\n",
      "\tspeed: 0.0343s/iter; left time: 3369.9353s\n",
      "\titers: 600, epoch: 5 | loss: 0.1088678\n",
      "\tspeed: 0.0306s/iter; left time: 3002.4971s\n",
      "\titers: 700, epoch: 5 | loss: 0.1040623\n",
      "\tspeed: 0.0306s/iter; left time: 3005.4708s\n",
      "\titers: 800, epoch: 5 | loss: 0.1087640\n",
      "\tspeed: 0.0317s/iter; left time: 3104.2122s\n",
      "\titers: 900, epoch: 5 | loss: 0.1394818\n",
      "\tspeed: 0.0353s/iter; left time: 3453.4085s\n",
      "\titers: 1000, epoch: 5 | loss: 0.1188958\n",
      "\tspeed: 0.0331s/iter; left time: 3235.2078s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1115984\n",
      "\tspeed: 0.0392s/iter; left time: 3831.4954s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0841511\n",
      "\tspeed: 0.0368s/iter; left time: 3595.0642s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1100051\n",
      "\tspeed: 0.0515s/iter; left time: 5022.7312s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0923641\n",
      "\tspeed: 0.0615s/iter; left time: 5998.1175s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1117724\n",
      "\tspeed: 0.0506s/iter; left time: 4926.9096s\n",
      "\titers: 1600, epoch: 5 | loss: 0.1076189\n",
      "\tspeed: 0.0388s/iter; left time: 3776.4030s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0866683\n",
      "\tspeed: 0.0385s/iter; left time: 3744.7626s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0916811\n",
      "\tspeed: 0.0419s/iter; left time: 4062.1883s\n",
      "\titers: 1900, epoch: 5 | loss: 0.1162998\n",
      "\tspeed: 0.0340s/iter; left time: 3297.1215s\n",
      "\titers: 2000, epoch: 5 | loss: 0.1157482\n",
      "\tspeed: 0.0327s/iter; left time: 3162.8814s\n",
      "\titers: 2100, epoch: 5 | loss: 0.1098212\n",
      "\tspeed: 0.0309s/iter; left time: 2985.2027s\n",
      "Epoch: 5 cost time: 82.66512894630432\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_SOFTS_96_96<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "loading model from ./checkpoints/ETTm1_SOFTS_96_96/checkpoint.pth\n",
      "rmse:0.5345862657740525, mae:0.35867902898031984, huber:0.13361184783230987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5345862657740525, 0.35867902898031984, 0.13361184783230987)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp = Exp_Custom(args)\n",
    "setting = f'{args.data}_{args.model}_{args.seq_len}_{args.pred_len}'\n",
    "print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "Exp.train(setting=setting, train_data=train_data, vali_data=vali_data, test_data=test_data)\n",
    "print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "Exp.test(setting=setting, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25a79ea1985454",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. Get predictions by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0926408d8d19bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:02:53.941063400Z",
     "start_time": "2024-06-13T12:02:52.983911800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ./checkpoints/ETTm1_SOFTS_96_96/checkpoint.pth\n",
      "(11521, 96, 7)\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "predictions = Exp.predict(setting=setting, pred_data=test_data)\n",
    "print(predictions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
